{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a97248-ee60-4f53-b539-14828729388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "device = 'model_display' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae472cd-cc43-49ff-a636-7d25df34cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69cd1b7d-1a4f-4075-a5e7-71a05a747234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0484\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# matrix operation \n",
    "zeros = torch.zeros(1, 1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb326e-8164-401b-b682-3939e24f8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### why we use gpu rather than cpu for training efficiency ?\n",
    "torch_rand1 = torch.rand(10000, 10000).to(device)\n",
    "torch_rand2 = torch.rand(10000, 10000).to(device)\n",
    "\n",
    "np_rand1 = np.random.randint(0, 100, size = (10000, 10000))\n",
    "np_rand2 = np.random.randint(0, 100, size = (10000, 10000))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rand = (torch_rand1 @ torch_rand2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time: .4f}\")\n",
    "\n",
    "###############################\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rand = np.multiply(np_rand1, np_rand2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time: .4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb0ca40-160a-40b5-a59e-e5199366d6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# define a probability in tensore\n",
    "probabilities = torch.tensor([0.1, 0.9]) # index 0 : 10% probability for 0, index 1: 90% probability for 1\n",
    "\n",
    "## draw 5 samples from a multinomial distributions\n",
    "samples = torch.multinomial(probabilities, num_samples = 10, replacement = True)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bed7f4a-52aa-491f-a261-d88dab81ff42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## concatination\n",
    "tensor = torch.tensor([1, 2, 3, 4]) # <- first tensor and second tensor is : torch.tensor([5]) \n",
    "out = torch.cat((tensor, torch.tensor([5])), dim = 0) # list of number will be concatinated with 5 row wise (dim = 0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc53b3b0-ac33-426f-ade5-07467ac0d064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tril(torch.ones(5, 5)) # triangle lower -> tril , triangle upper -> triu\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeef9353-280c-4885-96ae-b244123d16d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.triu(torch.ones(5, 5))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b1cafa-faa3-4a0f-9b14-188561371ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.zeros(5,5).masked_fill(torch.tril(torch.ones(5, 5)) == 0, float('-inf')) ## fil lower triangle with 0 and upper tri with infinity\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b54e4b0-eb55-4268-9e21-ef162d281d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## exponentiate\n",
    "torch.exp(out) ## anything exponentiate with 0 become 1, and exponentiate with -inf become 0\n",
    "## for example:\n",
    "## 2.71 exponent 0 = 1\n",
    "## 2.71 exponent 1 = 2.71\n",
    "## 2.71 exponent -inf = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da4be466-5959-4006-a9ee-9b222f100e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.zeros(2, 3, 4) ## 3 dim -- 2 matrix with 3 x 4 (3 rows, 4 columns)\n",
    "out = input.transpose(0, 2) ## (4 x 3 x 2) swap 0th position to 2nd position -- means 4 will swap with 2 (2, 3, 4) ---> (4, 3, 2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67429f60-1142-4816-8e8f-59ecaeeba02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "tensor3 = torch.tensor([7, 8, 9])\n",
    "\n",
    "# stacked the tensor along the new dimension\n",
    "stacked_tensor = torch.stack([tensor1, tensor2, tensor3])\n",
    "stacked_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a995edb-26b5-44e1-9bf3-7137b554d0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.2240,  3.7876,  2.8245], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "##layers\n",
    "import torch.nn as nn\n",
    "sample = torch.tensor([10., 10., 10.])\n",
    "linear = nn.Linear(3, 3, bias = False)\n",
    "print(linear(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ad2dc8-cf60-4f8f-b81d-70ca25022aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "tensor1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "softmax_output = F.softmax(tensor1, dim = 0)\n",
    "\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae8a8805-c184-4753-921b-d05bcf0e40ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f34f4ee6-95be-474a-9e35-1c774dafd7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.6191e-01,  8.0122e-01, -2.2010e+00, -1.6895e-01, -6.2045e-01,\n",
      "          1.0217e+00,  5.8735e-02,  6.4237e-01,  3.2018e-01, -8.8277e-01,\n",
      "         -1.5027e-01, -2.1337e+00, -8.6560e-01, -1.0648e-01, -1.7634e+00,\n",
      "          8.8613e-01,  4.1126e-01,  1.1649e+00, -5.3293e-01,  5.0122e-01,\n",
      "          2.9549e+00,  1.1305e-01, -1.0819e+00, -7.2212e-01,  6.1138e-01,\n",
      "          6.8825e-01, -2.2717e+00,  6.1363e-02, -5.9188e-01,  7.2158e-01,\n",
      "         -1.4191e-01, -1.6107e+00,  3.0306e-01, -1.9135e-01, -3.0990e-02,\n",
      "         -2.2375e+00,  1.7247e+00, -8.3924e-01,  1.4612e+00,  4.8080e-01,\n",
      "          1.3472e+00, -1.2980e+00,  1.6452e+00, -8.8469e-01, -9.2030e-01,\n",
      "         -4.7272e-02, -6.6451e-02,  2.5142e-01, -3.5029e-01, -9.6019e-01,\n",
      "         -1.7241e-01, -2.0314e+00,  5.0247e-01,  5.5936e-01,  1.0249e-01,\n",
      "          4.5128e-01, -9.8697e-02,  1.3945e+00,  8.5993e-01, -1.0973e+00,\n",
      "          4.0466e-01, -3.8623e-01,  5.9895e-01, -9.3674e-02, -4.9169e-02,\n",
      "         -3.9592e-01,  3.2144e-02,  3.3815e-01,  2.6915e-01,  1.2357e-01,\n",
      "          9.6026e-01, -5.6129e-01, -2.6220e+00,  8.7069e-01, -4.2968e-01,\n",
      "         -5.7192e-01, -6.8289e-01, -3.8751e-01, -8.1199e-01,  1.0489e+00,\n",
      "          1.3829e+00, -1.2099e+00,  1.2169e+00, -7.5474e-02,  1.2059e+00,\n",
      "         -1.7752e+00,  1.2432e+00, -1.5106e-02,  3.0447e-01, -1.6549e+00,\n",
      "         -8.1342e-01, -3.9682e-01,  7.7559e-01, -7.8716e-01, -1.3539e-01,\n",
      "          9.5337e-01, -3.7827e-01,  1.7619e+00, -2.2382e-01,  1.0959e-01],\n",
      "        [ 1.8311e+00,  1.0149e-01, -1.3691e+00, -1.2545e+00,  1.1447e+00,\n",
      "          5.9882e-01,  3.1590e-01,  4.4173e-01, -7.4826e-02,  1.4229e+00,\n",
      "         -1.2152e+00, -1.4482e-01, -9.6649e-02, -1.3256e+00,  9.9836e-01,\n",
      "          1.6539e+00, -6.8305e-01, -1.5768e+00, -1.4393e+00, -1.6161e+00,\n",
      "          3.2805e-01,  1.7413e-01, -1.5944e+00, -1.7977e-01,  1.7179e-01,\n",
      "         -5.8278e-01,  1.0495e-01, -3.9558e-01,  1.7634e-01,  5.4815e-02,\n",
      "         -1.6465e-01,  1.3131e-01,  8.6028e-01,  5.7612e-01, -8.8877e-01,\n",
      "         -4.2434e-01, -3.6887e-01, -1.5399e+00,  1.5224e-01,  3.7133e-01,\n",
      "          1.0017e+00,  5.9570e-01,  5.1978e-01,  5.0584e-01, -6.5240e-01,\n",
      "          2.8245e-01, -1.5442e+00,  3.3407e-01,  1.3407e+00, -1.2037e-01,\n",
      "          1.4745e+00, -6.8217e-01,  1.4821e+00, -4.3918e-01,  8.2013e-01,\n",
      "         -6.0558e-01,  8.4553e-01,  3.7218e-01,  1.6594e-03, -8.0899e-03,\n",
      "         -8.3247e-01, -5.9221e-02,  2.3329e-01,  1.4422e+00,  2.0594e-01,\n",
      "         -5.6887e-01, -1.0812e+00, -3.1705e-01, -2.7608e-01, -1.2890e+00,\n",
      "          1.8372e+00,  1.9541e+00,  6.1839e-01, -3.1201e-01,  8.0654e-01,\n",
      "          4.7467e-01,  4.3396e-02, -7.4642e-01, -1.5213e-01, -1.1946e+00,\n",
      "         -1.1029e+00,  9.6451e-02,  1.0903e+00,  1.8477e+00,  2.0662e+00,\n",
      "         -1.9918e+00,  8.2374e-01,  7.5298e-01, -3.3322e-01,  1.0669e+00,\n",
      "          3.6835e-02,  2.9998e+00, -1.9981e+00,  6.0352e-03,  8.7428e-01,\n",
      "          3.0689e-01, -6.9718e-01, -5.5187e-01,  8.4853e-01,  2.7736e-01],\n",
      "        [-1.1012e+00, -1.7335e+00, -1.4224e-01,  1.6926e-01,  1.3441e+00,\n",
      "          2.0994e+00,  1.8295e+00,  1.5168e+00, -1.4647e+00, -5.4150e-01,\n",
      "          3.2613e-01, -3.5774e-01,  4.2645e-02, -2.8058e-01,  1.7966e+00,\n",
      "          2.3549e-01, -8.7430e-01,  4.4894e-01, -9.7312e-01, -1.3719e+00,\n",
      "          3.0776e-01,  4.5510e-01, -2.0007e+00,  2.0971e-01, -8.7947e-01,\n",
      "         -2.2484e-01, -6.4398e-01, -9.7335e-01,  7.6595e-02, -1.0911e-01,\n",
      "         -1.2557e+00, -1.2975e+00,  9.4336e-01,  1.9607e-01,  4.3962e-01,\n",
      "          1.5969e-01, -5.8766e-02,  2.1904e+00,  7.0012e-01,  5.1595e-01,\n",
      "          1.0325e+00, -9.1525e-01,  4.3435e-01,  1.0500e+00,  9.8890e-01,\n",
      "          5.5867e-01, -6.3083e-01,  1.7682e-01,  4.6127e-01,  5.2095e-01,\n",
      "          1.0836e+00,  1.8825e+00, -3.7077e-01,  2.0307e+00,  1.4780e+00,\n",
      "         -4.0560e-02, -4.9863e-01,  6.4193e-01, -8.8857e-01,  1.6858e+00,\n",
      "         -1.1220e+00,  1.2290e+00, -6.9905e-01,  1.9310e+00, -1.0728e+00,\n",
      "         -7.0213e-01,  1.1839e+00,  2.9005e-02, -7.6676e-01,  4.3657e-01,\n",
      "         -5.0781e-02,  6.1524e-01, -5.4208e-01,  4.7744e-01, -9.7211e-01,\n",
      "          1.5418e-01, -6.6003e-01, -2.0292e+00,  1.1082e+00, -3.1009e-01,\n",
      "         -2.7610e-01, -2.2296e+00, -3.7263e-02,  1.5286e+00, -1.8374e+00,\n",
      "         -1.0327e+00,  8.7238e-01, -1.2994e-01, -4.9275e-01, -2.4980e-01,\n",
      "          5.6722e-02, -1.2112e+00,  2.6767e-02, -8.4642e-01, -7.2729e-01,\n",
      "          8.4325e-01,  8.7987e-02, -3.6214e-01,  5.7918e-01,  9.8579e-02],\n",
      "        [-6.5289e-01,  4.7900e-01, -6.8558e-01,  1.2168e+00, -1.9472e+00,\n",
      "          6.1640e-01,  5.9511e-01,  1.0470e+00,  1.2142e+00, -5.2692e-01,\n",
      "         -1.2664e+00, -4.5746e-01,  5.8012e-01, -9.7369e-01,  6.8543e-01,\n",
      "         -1.3239e+00,  1.6183e+00, -6.9402e-01,  7.3576e-01, -2.7581e-01,\n",
      "         -2.9655e-01,  9.3787e-02, -8.7052e-01, -3.0836e-01, -6.7503e-01,\n",
      "         -6.5835e-01,  1.6570e+00, -1.2910e+00,  1.5892e+00,  2.0758e+00,\n",
      "          3.0829e-01,  5.7727e-01,  8.8482e-01, -6.6646e-01,  3.4578e-01,\n",
      "          8.9896e-01,  6.2220e-02, -1.2857e+00,  1.2317e+00, -7.7431e-01,\n",
      "         -2.1903e-01, -5.3259e-01, -2.1828e-01,  4.4093e-01,  1.5705e-01,\n",
      "          7.6650e-01,  8.1077e-02,  1.2933e+00,  5.0086e-02,  1.0643e+00,\n",
      "         -1.7341e+00,  3.0423e-01,  8.0845e-01,  8.4793e-01,  2.9905e-01,\n",
      "         -2.0045e+00, -8.2742e-01,  8.0925e-01,  9.0868e-01, -8.1768e-01,\n",
      "          7.3979e-01, -5.4686e-02, -9.2118e-01, -5.1165e-01, -7.7621e-01,\n",
      "         -1.0548e-01,  2.6600e+00, -3.2614e-01, -2.5637e+00, -6.0545e-01,\n",
      "          4.6974e-01, -4.3092e-01,  8.3313e-02,  1.5892e+00,  1.5073e+00,\n",
      "          2.5507e+00,  6.3981e-01, -1.3722e+00,  1.1014e+00,  6.0003e-01,\n",
      "          3.6588e-01,  8.4901e-01,  8.5889e-01,  7.0032e-01, -9.2053e-01,\n",
      "         -9.7088e-01, -5.9858e-01,  9.0775e-01, -1.7935e-01,  3.2116e-01,\n",
      "          3.5329e-02, -8.6516e-01, -1.5656e-01, -2.7419e-01, -1.6548e+00,\n",
      "          3.5520e-01, -5.8504e-01,  5.4423e-01, -4.7518e-01, -4.7904e-01],\n",
      "        [ 2.5406e-02,  4.3977e-01,  7.8590e-01,  7.5403e-01,  1.6385e+00,\n",
      "          6.1214e-01,  3.7511e-01,  1.0559e+00,  2.8608e-01, -9.5890e-01,\n",
      "          1.1778e-01,  6.0526e-01,  2.4565e-01,  5.5376e-01, -5.3154e-01,\n",
      "          2.4451e-01,  7.9173e-01,  1.7697e-01, -1.5359e+00,  2.1661e-01,\n",
      "         -1.9149e+00, -5.4131e-01,  2.3242e+00, -1.6826e+00,  6.2135e-01,\n",
      "          1.3077e-01, -3.6313e-01,  1.4694e+00, -4.8396e-01, -1.4935e+00,\n",
      "         -6.5793e-01, -6.3408e-01,  5.9699e-01,  1.5170e+00, -2.9233e-01,\n",
      "         -5.1650e-01, -8.9091e-01,  1.5122e+00, -7.9100e-02,  3.8169e-01,\n",
      "          2.4609e-01, -6.3239e-01,  6.0494e-01,  1.9111e+00, -9.0965e-01,\n",
      "          4.8351e-01, -9.8672e-01, -8.8049e-01, -2.6355e-01,  1.8418e+00,\n",
      "          1.5285e-01, -1.8800e-01, -6.4251e-02,  8.9319e-01,  2.9144e-01,\n",
      "          1.5486e+00,  1.1264e+00,  7.8068e-01,  2.1129e+00,  1.0139e+00,\n",
      "          9.3537e-01,  1.2328e+00,  3.4346e-01, -4.8465e-01,  1.4296e+00,\n",
      "          6.8433e-01, -1.1361e+00,  1.8392e-01,  8.7510e-01,  3.0905e-01,\n",
      "          1.0617e+00,  3.9720e-01,  2.0470e+00,  2.4357e-01, -9.2935e-01,\n",
      "         -6.7508e-01, -1.9829e+00, -8.1746e-01,  5.9971e-01, -1.2614e+00,\n",
      "         -3.4296e-01, -6.3290e-01,  1.8815e+00, -1.2013e+00,  2.4151e-01,\n",
      "          2.6114e-03, -9.2702e-01,  5.3654e-01,  3.3694e-01,  8.4161e-01,\n",
      "         -7.1830e-01, -1.6644e+00,  8.0948e-01,  4.0343e-01,  6.4318e-01,\n",
      "         -3.6601e-01, -2.2426e+00,  1.8335e-01,  1.9806e+00, -3.0312e-01]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "## embedding -- text as vector\n",
    "\n",
    "\n",
    "# Define the size of the vocabulary and the dimensionality of the embeddings\n",
    "vocab_size = 1000  # Example: 10,000 unique words\n",
    "embedding_dim = 100  # Example: 100-dimensional embeddings -- each word will represent by a vector of length 100\n",
    "\n",
    "# Create an instance of the Embedding module\n",
    "embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "# Generate some example input indices\n",
    "input_indices = torch.tensor([1, 5, 3, 7, 2]) ## ech index refers to an unique word\n",
    "\n",
    "# Pass the input indices through the embedding layer\n",
    "embedded_vectors = embedding_layer(input_indices)\n",
    "\n",
    "print(embedded_vectors)\n",
    "print(embedded_vectors.shape)  # Output shape: (5, 100) - 5 input indices, each mapped to a 100-dimensional vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09989244-a1d8-42b6-a2f7-03234dbe6e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "source": [
    "### dot product\n",
    "a = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824f023b-8992-4870-a63c-d83b6770ef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b32570-355d-4c0c-8329-cd1bb768a54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "##int_64 = torch.randint(1, (3, 2)) ## --- ERROR\n",
    "# after casting\n",
    "int_64 = torch.randint(1, (3, 2)).float()\n",
    "float_32 = torch.rand(2, 3)\n",
    "\n",
    "result = torch.matmul(int_64, float_32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7f04a-82d8-4194-96f4-568767b583fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_display",
   "language": "python",
   "name": "my_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
